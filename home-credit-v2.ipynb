{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:52:16.455953Z","iopub.execute_input":"2021-06-28T11:52:16.45674Z","iopub.status.idle":"2021-06-28T11:52:17.35596Z","shell.execute_reply.started":"2021-06-28T11:52:16.456597Z","shell.execute_reply":"2021-06-28T11:52:17.354782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering/","metadata":{}},{"cell_type":"code","source":"!pip install modin[ray]\nimport modin.pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:52:17.357858Z","iopub.execute_input":"2021-06-28T11:52:17.358194Z","iopub.status.idle":"2021-06-28T11:53:01.546311Z","shell.execute_reply.started":"2021-06-28T11:52:17.358147Z","shell.execute_reply":"2021-06-28T11:53:01.544845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:01.548459Z","iopub.execute_input":"2021-06-28T11:53:01.548802Z","iopub.status.idle":"2021-06-28T11:53:01.5669Z","shell.execute_reply.started":"2021-06-28T11:53:01.548758Z","shell.execute_reply":"2021-06-28T11:53:01.565477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset\n* ``bureau``: information about client's previous loans with other financial institutions reported to Home Credit. Each previous loan has its own row.\n* ``bureau_balance``: monthly information about the previous loans. Each month has its own row.","metadata":{}},{"cell_type":"code","source":"bureau = pd.read_csv('../input/home-credit-default-risk/bureau.csv')\nbureau.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:01.568833Z","iopub.execute_input":"2021-06-28T11:53:01.569225Z","iopub.status.idle":"2021-06-28T11:53:09.19964Z","shell.execute_reply.started":"2021-06-28T11:53:01.569162Z","shell.execute_reply":"2021-06-28T11:53:09.198134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:09.203041Z","iopub.execute_input":"2021-06-28T11:53:09.204761Z","iopub.status.idle":"2021-06-28T11:53:09.214367Z","shell.execute_reply.started":"2021-06-28T11:53:09.204676Z","shell.execute_reply":"2021-06-28T11:53:09.21313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:09.21723Z","iopub.execute_input":"2021-06-28T11:53:09.218274Z","iopub.status.idle":"2021-06-28T11:53:09.869016Z","shell.execute_reply.started":"2021-06-28T11:53:09.218234Z","shell.execute_reply":"2021-06-28T11:53:09.866123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:09.870645Z","iopub.execute_input":"2021-06-28T11:53:09.870953Z","iopub.status.idle":"2021-06-28T11:53:12.697017Z","shell.execute_reply.started":"2021-06-28T11:53:09.870921Z","shell.execute_reply":"2021-06-28T11:53:12.695641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:12.69971Z","iopub.execute_input":"2021-06-28T11:53:12.700026Z","iopub.status.idle":"2021-06-28T11:53:13.250532Z","shell.execute_reply.started":"2021-06-28T11:53:12.699994Z","shell.execute_reply":"2021-06-28T11:53:13.249025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_loan_count = bureau.groupby('SK_ID_CURR',as_index=False)['SK_ID_BUREAU'].count()\npre_loan_count = pre_loan_count.rename(columns={'SK_ID_BUREAU':'prev_loan_count'})\npre_loan_count","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:13.252763Z","iopub.execute_input":"2021-06-28T11:53:13.25305Z","iopub.status.idle":"2021-06-28T11:53:13.745308Z","shell.execute_reply.started":"2021-06-28T11:53:13.253021Z","shell.execute_reply":"2021-06-28T11:53:13.743764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\napp = app.merge(pre_loan_count, on='SK_ID_CURR', how='left')\napp.prev_loan_count = app.prev_loan_count.fillna(0)\napp.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:13.74685Z","iopub.execute_input":"2021-06-28T11:53:13.747265Z","iopub.status.idle":"2021-06-28T11:53:20.17657Z","shell.execute_reply.started":"2021-06-28T11:53:13.747224Z","shell.execute_reply":"2021-06-28T11:53:20.17533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kernel_plot(var_name, df):\n    print('correlation of {0} with target {1}'.format(var_name, app['TARGET'].corr(app.prev_loan_count)))\n    repaid_median = df.loc[df['TARGET']==0, var_name].median()\n    not_repaid = df.loc[df['TARGET']==1, var_name].median()\n    print('median value for repaid ',repaid_median)\n    print('median value for not repaid ',not_repaid)\n    sns.kdeplot(df.loc[df['TARGET']==0, var_name],label='target=0')\n    sns.kdeplot(df.loc[df['TARGET']==1, var_name], label='target=1')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:20.177837Z","iopub.execute_input":"2021-06-28T11:53:20.178196Z","iopub.status.idle":"2021-06-28T11:53:20.18688Z","shell.execute_reply.started":"2021-06-28T11:53:20.178144Z","shell.execute_reply":"2021-06-28T11:53:20.18557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_plot('prev_loan_count',app)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:20.188471Z","iopub.execute_input":"2021-06-28T11:53:20.189371Z","iopub.status.idle":"2021-06-28T11:53:26.404476Z","shell.execute_reply.started":"2021-06-28T11:53:20.189328Z","shell.execute_reply":"2021-06-28T11:53:26.402713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_plot('EXT_SOURCE_3',app)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:26.405947Z","iopub.execute_input":"2021-06-28T11:53:26.406308Z","iopub.status.idle":"2021-06-28T11:53:37.611546Z","shell.execute_reply.started":"2021-06-28T11:53:26.40627Z","shell.execute_reply":"2021-06-28T11:53:37.606565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Aggregating Numeric Columns\nTo account for the numeric information in the bureau dataframe, we can compute statistics for all the numeric columns. To do so, we groupby the client id, agg the grouped dataframe, and merge the result back into the training data. The agg function will only calculate the values for the numeric columns where the operation is considered valid. We will stick to using 'mean', 'max', 'min', 'sum' but any function can be passed in here. We can even write our own function and use it in an agg call.","metadata":{}},{"cell_type":"code","source":"bureau.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:37.620548Z","iopub.execute_input":"2021-06-28T11:53:37.621914Z","iopub.status.idle":"2021-06-28T11:53:37.806253Z","shell.execute_reply.started":"2021-06-28T11:53:37.621866Z","shell.execute_reply":"2021-06-28T11:53:37.80487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_agg = bureau.drop('SK_ID_BUREAU',axis=1).groupby('SK_ID_CURR',as_index=False).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\nbureau_agg.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:37.807798Z","iopub.execute_input":"2021-06-28T11:53:37.808138Z","iopub.status.idle":"2021-06-28T11:53:48.641815Z","shell.execute_reply.started":"2021-06-28T11:53:37.808107Z","shell.execute_reply":"2021-06-28T11:53:48.640341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of column names\ncolumns = ['SK_ID_CURR']\n\n# Iterate through the variables names\nfor var in bureau_agg.columns.levels[0]:\n    # Skip the id name\n    if var != 'SK_ID_CURR':\n        \n        # Iterate through the stat names\n        for stat in bureau_agg.columns.levels[1][:-1]:\n            # Make a new column name for the variable and stat\n            columns.append('bureau_%s_%s' % (var, stat))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:48.644369Z","iopub.execute_input":"2021-06-28T11:53:48.645201Z","iopub.status.idle":"2021-06-28T11:53:48.654Z","shell.execute_reply.started":"2021-06-28T11:53:48.645114Z","shell.execute_reply":"2021-06-28T11:53:48.652798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['SK_ID_CURR']\n\nfor var in bureau_agg.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in bureau_agg.columns.levels[1][:-1]:\n            columns.append('bureau_%s_%s' %(var,stat))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:48.655795Z","iopub.execute_input":"2021-06-28T11:53:48.656165Z","iopub.status.idle":"2021-06-28T11:53:48.67163Z","shell.execute_reply.started":"2021-06-28T11:53:48.65613Z","shell.execute_reply":"2021-06-28T11:53:48.669918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:48.673734Z","iopub.execute_input":"2021-06-28T11:53:48.674096Z","iopub.status.idle":"2021-06-28T11:53:48.687825Z","shell.execute_reply.started":"2021-06-28T11:53:48.674013Z","shell.execute_reply":"2021-06-28T11:53:48.686031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_agg.columns=columns\nbureau_agg.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:48.68948Z","iopub.execute_input":"2021-06-28T11:53:48.68991Z","iopub.status.idle":"2021-06-28T11:53:48.865498Z","shell.execute_reply.started":"2021-06-28T11:53:48.689867Z","shell.execute_reply":"2021-06-28T11:53:48.864693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app = app.merge(bureau_agg, on='SK_ID_CURR', how='left')\napp.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:48.867031Z","iopub.execute_input":"2021-06-28T11:53:48.867597Z","iopub.status.idle":"2021-06-28T11:53:53.848294Z","shell.execute_reply.started":"2021-06-28T11:53:48.86756Z","shell.execute_reply":"2021-06-28T11:53:53.846966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_corr = []\nfor col in columns:\n    corr = app['TARGET'].corr(app[col])\n    new_corr.append([col,corr])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:53:53.850544Z","iopub.execute_input":"2021-06-28T11:53:53.850991Z","iopub.status.idle":"2021-06-28T11:56:58.267985Z","shell.execute_reply.started":"2021-06-28T11:53:53.850947Z","shell.execute_reply":"2021-06-28T11:56:58.26679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_corr = pd.DataFrame(new_corr).sort_values(1,ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:56:58.270173Z","iopub.execute_input":"2021-06-28T11:56:58.270882Z","iopub.status.idle":"2021-06-28T11:56:58.351738Z","shell.execute_reply.started":"2021-06-28T11:56:58.270833Z","shell.execute_reply":"2021-06-28T11:56:58.348365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_corr.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:56:58.359511Z","iopub.execute_input":"2021-06-28T11:56:58.360285Z","iopub.status.idle":"2021-06-28T11:56:58.397811Z","shell.execute_reply.started":"2021-06-28T11:56:58.360234Z","shell.execute_reply":"2021-06-28T11:56:58.397029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_plot('bureau_DAYS_CREDIT_mean',app)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:56:58.400997Z","iopub.execute_input":"2021-06-28T11:56:58.401591Z","iopub.status.idle":"2021-06-28T11:57:05.623412Z","shell.execute_reply.started":"2021-06-28T11:56:58.401557Z","shell.execute_reply":"2021-06-28T11:57:05.621553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:57:05.625334Z","iopub.execute_input":"2021-06-28T11:57:05.625732Z","iopub.status.idle":"2021-06-28T11:57:09.568983Z","shell.execute_reply.started":"2021-06-28T11:57:05.62569Z","shell.execute_reply":"2021-06-28T11:57:09.567455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:57:09.570717Z","iopub.execute_input":"2021-06-28T11:57:09.57102Z","iopub.status.idle":"2021-06-28T11:57:09.583935Z","shell.execute_reply.started":"2021-06-28T11:57:09.570988Z","shell.execute_reply":"2021-06-28T11:57:09.582706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function for Numeric Aggregations","metadata":{}},{"cell_type":"code","source":"def agg_numeric(df, group_var, df_name):\n    # Iterate through the variables names\n    for var in agg.columns.levels[0]:\n        # Skip the grouping variable\n        if var != group_var:\n            # Iterate through the stat names\n            for stat in agg.columns.levels[1][:-1]:\n                # Make a new column name for the variable and stat\n                columns.append('%s_%s_%s' % (df_name, var, stat))\n\n    agg.columns = columns\n    return agg","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:57:09.585888Z","iopub.execute_input":"2021-06-28T11:57:09.58631Z","iopub.status.idle":"2021-06-28T11:57:09.732545Z","shell.execute_reply.started":"2021-06-28T11:57:09.58627Z","shell.execute_reply":"2021-06-28T11:57:09.729683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def agg_numeric(df,group_var,df_name):\n    # remove id variable other than grouping variable\n    for col in df:\n        if col != group_var and 'SK_ID' in col:\n            df = df.drop(columns = col)\n    \n    group_ids = df[group_var]\n    numeric_df = df.select_dtypes('number')\n    numeric_df[group_var] = group_ids\n\n    # group by group_var and create their aggergates\n    agg = numeric_df.groupby(group_var).agg(['count','mean','max','min','sum']).reset_index()\n\n    #create new columns\n    columns = [group_var]\n    \n    # iter through variable names\n    for var in agg.columns.levels[0]:\n        if var != group_var:\n            for stat in agg.columns.levels[1][:-1]:\n                columns.append('%s_%s_%s'%(df_name, var, stat))\n    agg.columns = columns\n    return agg\n    \n    \"\"\"\n    Return\n    --------\n        agg (dataframe): \n            a dataframe with the statistics aggregated for \n            all numeric columns. Each instance of the grouping variable will have \n            the statistics (mean, min, max, sum; currently supported) calculated. \n            The columns are also renamed to keep track of features created.\n    \n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:57:09.734137Z","iopub.execute_input":"2021-06-28T11:57:09.734503Z","iopub.status.idle":"2021-06-28T11:57:09.777636Z","shell.execute_reply.started":"2021-06-28T11:57:09.734466Z","shell.execute_reply":"2021-06-28T11:57:09.774657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_agg_new = agg_numeric(bureau.drop('SK_ID_BUREAU',axis=1),group_var='SK_ID_CURR',df_name='bureau')\nbureau_agg_new.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:57:09.779401Z","iopub.execute_input":"2021-06-28T11:57:09.779829Z","iopub.status.idle":"2021-06-28T11:57:14.542847Z","shell.execute_reply.started":"2021-06-28T11:57:09.779782Z","shell.execute_reply":"2021-06-28T11:57:14.541983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_agg_new.bureau_DAYS_CREDIT_count.dtype == 'int64'","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:57:14.544112Z","iopub.execute_input":"2021-06-28T11:57:14.5445Z","iopub.status.idle":"2021-06-28T11:57:14.663567Z","shell.execute_reply.started":"2021-06-28T11:57:14.54447Z","shell.execute_reply":"2021-06-28T11:57:14.662388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def target_corr(df):\n    corr = []\n    for col in df:\n        if df[col].dtype=='int64':\n            if col != 'TARGET':\n                corr_val = df['TARGET'].corr(df[col])\n                corr.append([col,corr_val])\n    corr_df = pd.DataFrame(corr)\n#     ,columns={0:'Coumns name',1:'correlation_with_target'}\n    corr_df = corr_df.sort_values(1,ascending=False)\n    return corr_df","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:57:14.665251Z","iopub.execute_input":"2021-06-28T11:57:14.665559Z","iopub.status.idle":"2021-06-28T11:57:16.122848Z","shell.execute_reply.started":"2021-06-28T11:57:14.665528Z","shell.execute_reply":"2021-06-28T11:57:16.121639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_corr(app)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:57:16.124364Z","iopub.execute_input":"2021-06-28T11:57:16.124807Z","iopub.status.idle":"2021-06-28T11:58:39.079393Z","shell.execute_reply.started":"2021-06-28T11:57:16.124762Z","shell.execute_reply":"2021-06-28T11:58:39.078407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical Variables","metadata":{}},{"cell_type":"code","source":"bureau.select_dtypes('object')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:39.081132Z","iopub.execute_input":"2021-06-28T11:58:39.081698Z","iopub.status.idle":"2021-06-28T11:58:39.493855Z","shell.execute_reply.started":"2021-06-28T11:58:39.081646Z","shell.execute_reply":"2021-06-28T11:58:39.492912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical = pd.get_dummies(bureau.select_dtypes('object'))\ncategorical['SK_ID_CURR'] = bureau['SK_ID_CURR']\ncategorical.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:39.495123Z","iopub.execute_input":"2021-06-28T11:58:39.495494Z","iopub.status.idle":"2021-06-28T11:58:41.569327Z","shell.execute_reply.started":"2021-06-28T11:58:39.495464Z","shell.execute_reply":"2021-06-28T11:58:41.568375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_group = categorical.groupby('SK_ID_CURR').agg(['sum','mean'])\ncategorical_group.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:41.570352Z","iopub.execute_input":"2021-06-28T11:58:41.570733Z","iopub.status.idle":"2021-06-28T11:58:44.723123Z","shell.execute_reply.started":"2021-06-28T11:58:41.570705Z","shell.execute_reply":"2021-06-28T11:58:44.722276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_group.columns.levels[0][:10]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:44.724487Z","iopub.execute_input":"2021-06-28T11:58:44.7249Z","iopub.status.idle":"2021-06-28T11:58:44.730875Z","shell.execute_reply.started":"2021-06-28T11:58:44.724868Z","shell.execute_reply":"2021-06-28T11:58:44.729705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"group_var = 'SK_ID_CURR'\ncolumns = []\nfor var in categorical_group.columns.levels[0]:\n    if var != group_var:\n        for stat in ['sum','mean']:\n            columns.append('%s_%s'%(var,stat))\ncategorical_group.columns = columns\ncategorical_group.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:44.732157Z","iopub.execute_input":"2021-06-28T11:58:44.732472Z","iopub.status.idle":"2021-06-28T11:58:45.428381Z","shell.execute_reply.started":"2021-06-28T11:58:44.732444Z","shell.execute_reply":"2021-06-28T11:58:45.427394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app = app.merge(categorical_group, on='SK_ID_CURR', how='left')\napp.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:45.429623Z","iopub.execute_input":"2021-06-28T11:58:45.429949Z","iopub.status.idle":"2021-06-28T11:58:49.006813Z","shell.execute_reply.started":"2021-06-28T11:58:45.429907Z","shell.execute_reply":"2021-06-28T11:58:49.00591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:49.00808Z","iopub.execute_input":"2021-06-28T11:58:49.008562Z","iopub.status.idle":"2021-06-28T11:58:49.014377Z","shell.execute_reply.started":"2021-06-28T11:58:49.008515Z","shell.execute_reply":"2021-06-28T11:58:49.013084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### categorical function","metadata":{}},{"cell_type":"code","source":"def count_categorical(df,group_var,df_name):\n    \"\"\"\n    Return\n    --------\n    categorical : dataframe\n        A dataframe with counts and normalized counts of each unique category in every categorical variable\n        with one row for every unique value of the `group_var`.\n        \n    \"\"\"\n    categorical = pd.get_dummies(df.select_dtypes('object'))\n    categorical[group_var] = df[group_var]\n    categorical_group = categorical.groupby(group_var).agg(['sum','mean'])\n    \n    columns = []\n    for var in categorical_group.columns.levels[0]:\n        if var != group_var:\n            for stat in ['sum','mean']:\n                columns.append('%s_%s_%s'%(df_name,var,stat))\n    categorical_group.columns = columns\n    return categorical_group","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:49.016032Z","iopub.execute_input":"2021-06-28T11:58:49.016827Z","iopub.status.idle":"2021-06-28T11:58:49.028652Z","shell.execute_reply.started":"2021-06-28T11:58:49.016589Z","shell.execute_reply":"2021-06-28T11:58:49.02701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_counts.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T11:58:49.030558Z","iopub.execute_input":"2021-06-28T11:58:49.031391Z","iopub.status.idle":"2021-06-28T11:58:53.842855Z","shell.execute_reply.started":"2021-06-28T11:58:49.031115Z","shell.execute_reply":"2021-06-28T11:58:53.841576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pds","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:00:17.391287Z","iopub.execute_input":"2021-06-28T12:00:17.39173Z","iopub.status.idle":"2021-06-28T12:00:17.398392Z","shell.execute_reply.started":"2021-06-28T12:00:17.391665Z","shell.execute_reply":"2021-06-28T12:00:17.396818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"description = pds.read_csv('../input/home-credit-default-risk/HomeCredit_columns_description.csv')\ndescription","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:00:20.187806Z","iopub.execute_input":"2021-06-28T12:00:20.188161Z","iopub.status.idle":"2021-06-28T12:00:20.216232Z","shell.execute_reply.started":"2021-06-28T12:00:20.188131Z","shell.execute_reply":"2021-06-28T12:00:20.214647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read bureau_balance","metadata":{}},{"cell_type":"code","source":"bureau_balance = pd.read_csv('../input/home-credit-default-risk/bureau_balance.csv')\nbureau_balance.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:00:26.014369Z","iopub.execute_input":"2021-06-28T12:00:26.014769Z","iopub.status.idle":"2021-06-28T12:00:35.730083Z","shell.execute_reply.started":"2021-06-28T12:00:26.014736Z","shell.execute_reply":"2021-06-28T12:00:35.728622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(description.loc[description['Row']=='STATUS']['Description'])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:00:36.899837Z","iopub.execute_input":"2021-06-28T12:00:36.900302Z","iopub.status.idle":"2021-06-28T12:00:36.910319Z","shell.execute_reply.started":"2021-06-28T12:00:36.900267Z","shell.execute_reply":"2021-06-28T12:00:36.909069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_balance.STATUS.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:00:37.919154Z","iopub.execute_input":"2021-06-28T12:00:37.919555Z","iopub.status.idle":"2021-06-28T12:00:50.17933Z","shell.execute_reply.started":"2021-06-28T12:00:37.919521Z","shell.execute_reply":"2021-06-28T12:00:50.177976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_counts.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:00:50.181562Z","iopub.execute_input":"2021-06-28T12:00:50.18208Z","iopub.status.idle":"2021-06-28T12:01:10.1969Z","shell.execute_reply.started":"2021-06-28T12:00:50.182013Z","shell.execute_reply":"2021-06-28T12:01:10.195246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_balance_agg = agg_numeric(bureau_balance,'SK_ID_BUREAU','bureau_balance')\nbureau_balance_agg.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:01:10.198927Z","iopub.execute_input":"2021-06-28T12:01:10.199252Z","iopub.status.idle":"2021-06-28T12:01:17.605139Z","shell.execute_reply.started":"2021-06-28T12:01:10.199213Z","shell.execute_reply":"2021-06-28T12:01:17.604025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_counts.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:01:17.60684Z","iopub.execute_input":"2021-06-28T12:01:17.607159Z","iopub.status.idle":"2021-06-28T12:01:36.728289Z","shell.execute_reply.started":"2021-06-28T12:01:17.607123Z","shell.execute_reply":"2021-06-28T12:01:36.727092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bureau_balance_agg = agg_numeric(bureau_balance,'SK_ID_BUREAU','bureau_balance')\nbureau_balance_agg.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:01:36.729757Z","iopub.execute_input":"2021-06-28T12:01:36.730143Z","iopub.status.idle":"2021-06-28T12:01:44.298496Z","shell.execute_reply.started":"2021-06-28T12:01:36.7301Z","shell.execute_reply":"2021-06-28T12:01:44.297127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataframe grouped by the loan\nbureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index=True, left_on='SK_ID_BUREAU', how='outer')\n# Merge to include the SK_ID_CURR\nbureau_by_loan = bureau[['SK_ID_BUREAU','SK_ID_CURR']].merge(bureau_by_loan, on='SK_ID_BUREAU', how='left')\n# Aggregate the stats for each client\nbureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns=['SK_ID_BUREAU']), group_var='SK_ID_CURR',df_name='client')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:01:44.300276Z","iopub.execute_input":"2021-06-28T12:01:44.300844Z","iopub.status.idle":"2021-06-28T12:01:54.405137Z","shell.execute_reply.started":"2021-06-28T12:01:44.3008Z","shell.execute_reply":"2021-06-28T12:01:54.402751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insert Computed Features into Training Data","metadata":{}},{"cell_type":"code","source":"original_features = list(app.columns)\nprint('Total number of original features are',len(original_features))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:01:54.426616Z","iopub.execute_input":"2021-06-28T12:01:54.431374Z","iopub.status.idle":"2021-06-28T12:01:54.447811Z","shell.execute_reply.started":"2021-06-28T12:01:54.43131Z","shell.execute_reply":"2021-06-28T12:01:54.445074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WE already merge some columns so to avoid any complication i fist read app_train as a new df and then merge new calculated featues into it","metadata":{}},{"cell_type":"code","source":"app_train = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\napp_train.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:30:21.9376Z","iopub.execute_input":"2021-06-28T12:30:21.937999Z","iopub.status.idle":"2021-06-28T12:30:28.043364Z","shell.execute_reply.started":"2021-06-28T12:30:21.937964Z","shell.execute_reply":"2021-06-28T12:30:28.042628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_features = list(app_train.columns)\nprint('Total number of original features are',len(original_features))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:30:28.044685Z","iopub.execute_input":"2021-06-28T12:30:28.04515Z","iopub.status.idle":"2021-06-28T12:30:28.051769Z","shell.execute_reply.started":"2021-06-28T12:30:28.045093Z","shell.execute_reply":"2021-06-28T12:30:28.0502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train = app_train.merge(bureau_counts, on='SK_ID_CURR',how='left')\napp_train = app_train.merge(bureau_agg, on='SK_ID_CURR', how='left')\napp_train = app_train.merge(bureau_balance_by_client, on='SK_ID_CURR',how='left')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:30:28.05354Z","iopub.execute_input":"2021-06-28T12:30:28.053845Z","iopub.status.idle":"2021-06-28T12:30:44.723035Z","shell.execute_reply.started":"2021-06-28T12:30:28.053815Z","shell.execute_reply":"2021-06-28T12:30:44.717397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_features = list(app_train.columns)\nprint('Number of features using previous loans from other institutions data: ', len(new_features))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:30:44.725285Z","iopub.execute_input":"2021-06-28T12:30:44.725587Z","iopub.status.idle":"2021-06-28T12:30:44.739926Z","shell.execute_reply.started":"2021-06-28T12:30:44.725557Z","shell.execute_reply":"2021-06-28T12:30:44.733711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering Outcomes","metadata":{}},{"cell_type":"code","source":"def missing_values_table(df):\n    miss_val = df.isnull().sum()\n    miss_val_table = pd.DataFrame(miss_val)\n#     miss_val_table = miss_val_table.rename(columns={0:'Name of columns',1:'per_of_null'})\n    miss_val_table['per_of_null'] = 100*df.isnull().sum()/len(df)\n    miss_val_table = miss_val_table.sort_values('per_of_null',ascending=False)\n    print('Dataframe has '+ str(len(df.columns))+ ' columns and Null columns are ' + str(len(miss_val_table[miss_val_table['per_of_null']!=0])))\n    return miss_val_table","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:30:44.742462Z","iopub.execute_input":"2021-06-28T12:30:44.742952Z","iopub.status.idle":"2021-06-28T12:30:48.809653Z","shell.execute_reply.started":"2021-06-28T12:30:44.742904Z","shell.execute_reply":"2021-06-28T12:30:48.808495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"miss = missing_values_table(app_train)\nmiss.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:30:48.811283Z","iopub.execute_input":"2021-06-28T12:30:48.811712Z","iopub.status.idle":"2021-06-28T12:30:50.984045Z","shell.execute_reply.started":"2021-06-28T12:30:48.811666Z","shell.execute_reply":"2021-06-28T12:30:50.982761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take out columns name that has more than 90 data null\nmiss_train_var = miss.index[miss['per_of_null']>90]\nlen(miss_train_var)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:30:50.9857Z","iopub.execute_input":"2021-06-28T12:30:50.986155Z","iopub.status.idle":"2021-06-28T12:30:51.075198Z","shell.execute_reply.started":"2021-06-28T12:30:50.986109Z","shell.execute_reply":"2021-06-28T12:30:51.074341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train.to_csv('bureau+bureau_balance+app_train.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:30:51.078121Z","iopub.execute_input":"2021-06-28T12:30:51.078641Z","iopub.status.idle":"2021-06-28T12:31:32.400526Z","shell.execute_reply.started":"2021-06-28T12:30:51.07859Z","shell.execute_reply":"2021-06-28T12:31:32.398937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlations\n\nFirst let's look at the correlations of the variables with the target. We can see in any of the variables we created have a greater correlation than those already present in the training data (from application).","metadata":{}},{"cell_type":"code","source":"corr = app_train.corr()\ncorr = corr.sort_values('TARGET',ascending=False)\ncorr = pd.DataFrame(corr)\ncorr['TARGET'].head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:31:32.403165Z","iopub.execute_input":"2021-06-28T12:31:32.404438Z","iopub.status.idle":"2021-06-28T12:39:38.463597Z","shell.execute_reply.started":"2021-06-28T12:31:32.404379Z","shell.execute_reply":"2021-06-28T12:39:38.462163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Collinear Variables\nWe can calculate not only the correlations of the variables with the target, but also the correlation of each variable with every other variable. This will allow us to see if there are highly collinear variables that should perhaps be removed from the data.\n\nLet's look for any variables that have a greather than 0.8 correlation with other variables.","metadata":{}},{"cell_type":"code","source":"threshold = 0.8\nabove_threshold_var = {}\nfor col in corr:\n    above_threshold_var[col] = list(corr.index[corr[col] > threshold])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:39:38.46487Z","iopub.execute_input":"2021-06-28T12:39:38.465169Z","iopub.status.idle":"2021-06-28T12:39:58.259208Z","shell.execute_reply.started":"2021-06-28T12:39:38.465141Z","shell.execute_reply":"2021-06-28T12:39:58.258163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(above_threshold_var)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:39:58.260581Z","iopub.execute_input":"2021-06-28T12:39:58.261335Z","iopub.status.idle":"2021-06-28T12:39:58.269282Z","shell.execute_reply.started":"2021-06-28T12:39:58.261288Z","shell.execute_reply":"2021-06-28T12:39:58.268003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!lscpu |grep 'Model name'\n!lscpu | grep 'Core(s) per socket'\n!lscpu | grep 'Thread(s) per core'\n!lscpu | grep MHz\n!lscpu | grep 'L3 cache'\n!cat /proc/meminfo | grep 'MemAvailable'\n!df -h / | awk '{print $4}'","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:39:58.270974Z","iopub.execute_input":"2021-06-28T12:39:58.271546Z","iopub.status.idle":"2021-06-28T12:40:03.710492Z","shell.execute_reply.started":"2021-06-28T12:39:58.271503Z","shell.execute_reply":"2021-06-28T12:40:03.70932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_remove = []\ncols_seen = []\ncols_to_remove_pair = []\n\nfor key, value in above_threshold_var.items():\n    cols_seen.append(key)\n    for x in value:\n        if x == key:\n            next\n        else:\n            if x not in cols_seen:\n                cols_to_remove.append(x)\n                cols_to_remove_pair.append(key)\n                \ncols_to_remove = list(set(cols_to_remove))\nprint('Number of columns to remove: ', len(cols_to_remove))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:25:37.120762Z","iopub.execute_input":"2021-06-28T12:25:37.121164Z","iopub.status.idle":"2021-06-28T12:25:37.135822Z","shell.execute_reply.started":"2021-06-28T12:25:37.121129Z","shell.execute_reply":"2021-06-28T12:25:37.133882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train_removed = app_train.drop(columns=cols_to_remove)\napp_train_removed.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:40:03.712636Z","iopub.execute_input":"2021-06-28T12:40:03.713299Z","iopub.status.idle":"2021-06-28T12:40:03.745639Z","shell.execute_reply.started":"2021-06-28T12:40:03.71325Z","shell.execute_reply":"2021-06-28T12:40:03.744552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train.to_csv('train_bureau_corrs_removed.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:40:03.747647Z","iopub.execute_input":"2021-06-28T12:40:03.748055Z","iopub.status.idle":"2021-06-28T12:40:40.577024Z","shell.execute_reply.started":"2021-06-28T12:40:03.748019Z","shell.execute_reply":"2021-06-28T12:40:40.576019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling\nTo actually test the performance of these new datasets, we will try using them for machine learning! Here we will use a function I developed in another notebook to compare the features (the raw version with the highly correlated variables removed). We can run this kind of like an experiment, and the control will be the performance of just the application data in this function when submitted to the competition. I've already recorded that performance, so we can list out our control and our two test conditions:\n\n**For all datasets, use the model shown below (with the exact hyperparameters).**\n\n* control: only the data in the application files.\n* test one: the data in the application files with all of the data recorded from the bureau and bureau_balance files\n* test two: the data in the application files with all of the data recorded from the bureau and bureau_balance files with highly correlated variables removed.","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nimport gc\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-06-28T12:56:05.958022Z","iopub.execute_input":"2021-06-28T12:56:05.958507Z","iopub.status.idle":"2021-06-28T12:56:05.964586Z","shell.execute_reply.started":"2021-06-28T12:56:05.958457Z","shell.execute_reply":"2021-06-28T12:56:05.963793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model(features, encoding='ohe',n_folds=3):\n    ids = features['SK_ID_CURR']\n    labels = features['TARGET']\n    features = features.drop(columns =['SK_ID_CURR','TARGET'])\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        cat_indices= 'auto'\n    elif encoding == 'le':\n        label_encoder = LabelEncoder()\n        cat_indices = []\n        for i, col in enumerate(features):\n            if features[col].dtype == 'object':\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                cat_indices.append(i)\n                \n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")    \n    print('Training data shape: ',features.shape)\n    feature_names = list(features.columns)\n#     X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n    features = np.array(features)\n    k_fold = KFold(n_splits = n_folds, shuffle=False)\n\n    # Empty array for feature importances\n    feature_importance_values = np.zeros(len(feature_names))\n    \n    # Empty array for out of fold validation predictions\n    out_of_fold = np.zeros(features.shape[0])\n    \n    # Lists for recording validation and training scores\n    valid_scores = []\n    train_scores = []\n                         \n    for train_indices, valid_indices in k_fold.split(features):\n        train_features, train_labels = features[train_indices], labels[train_indices]\n        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n        model = lgb.LGBMClassifier(n_estimators=10000, objective='binary',\n                                   class_weight='balanced', learning_rate=0.05,\n                                   reg_alpha=0.1, reg_lambda=0.1,\n                                   subsample=0.8, n_jobs=-1, random_state=50)\n        model.fit(train_features, train_labels, eval_metric = 'auc',\n                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n                  early_stopping_rounds = 100, verbose = 200)\n        best_iteration = model.best_iteration_\n#         feature_importance_values += model.feature_importance() / k_fold.n_splits\n#         out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration=best_iteration)[:,1]\n#         # Record the best score\n#         valid_score = model.best_score_['valid']['auc']\n#         train_score = model.best_score_['train']['auc']\n        \n#         valid_scores.append(valid_score)\n#         train_scores.append(train_score)\n        \n#         # Clean up memory\n#         gc.enable()\n#         del model, train_features, valid_features\n#         gc.collect()\n#     # Make the feature importance dataframe\n#     feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    \n#     # Overall validation score\n#     valid_auc = roc_auc_score(labels, out_of_fold)\n    \n#     # Add the overall scores to the metrics\n#     valid_scores.append(valid_auc)\n#     train_scores.append(np.mean(train_scores))\n    \n#     # Needed for creating dataframe of validation scores\n#     fold_names = list(range(n_folds))\n#     fold_names.append('overall')\n    \n#     # Dataframe of validation scores\n#     metrics = pd.DataFrame({'fold': fold_names,\n#                             'train': train_scores,\n#                             'valid': valid_scores}) \n    \n#     return feature_importances, metrics","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:22:39.11843Z","iopub.execute_input":"2021-06-28T13:22:39.11912Z","iopub.status.idle":"2021-06-28T13:22:39.15063Z","shell.execute_reply.started":"2021-06-28T13:22:39.119062Z","shell.execute_reply":"2021-06-28T13:22:39.149344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Control\nThe first step in any experiment is establishing a control. For this we will use the function defined above (that implements a Gradient Boosting Machine model) and the single main data source (application).","metadata":{}},{"cell_type":"code","source":"# train_control = pds.read_csv('../input/home-credit-default-risk/application_train.csv')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-28T13:22:40.170115Z","iopub.execute_input":"2021-06-28T13:22:40.170958Z","iopub.status.idle":"2021-06-28T13:22:40.177064Z","shell.execute_reply.started":"2021-06-28T13:22:40.170918Z","shell.execute_reply":"2021-06-28T13:22:40.174585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fi, metrics = model(train_control)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:22:40.926431Z","iopub.execute_input":"2021-06-28T13:22:40.92709Z","iopub.status.idle":"2021-06-28T13:25:33.559093Z","shell.execute_reply.started":"2021-06-28T13:22:40.927029Z","shell.execute_reply":"2021-06-28T13:25:33.556756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}